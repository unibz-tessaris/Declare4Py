{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c020581-ca5e-4c1a-a32a-8b3fc9a3b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Declare4Py.Encodings.Aggregate import Aggregate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from Declare4Py.Encodings.IndexBased import IndexBased\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "max_ev = 20\n",
    "min_ev = 20\n",
    "max_padding = max_ev\n",
    "min_padding = 3\n",
    "padded_column_name = \"padding_len\"\n",
    "\n",
    "RNG = 0\n",
    "\n",
    "noise_list = [0, 5, 10, 15]\n",
    "\n",
    "padding_dict = {}\n",
    "f1_score_dict = {}\n",
    "\n",
    "encoders = {Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], boolean=True): \"Boolean\",\n",
    "            Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], boolean=False): \"Frequency\",\n",
    "            Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], num_cols=['valore', 'age'], boolean=False, aggregation_functions=['min', 'mean', 'max']): \"Aggregate\",\n",
    "            IndexBased(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], create_dummies=True): \"SimpleIdx\",\n",
    "            IndexBased(case_id_col=\"case:concept:name\", cat_cols = ['concept:name'], num_cols=['valore', 'age'], create_dummies=True): \"ComplexIdx\"}\n",
    "\n",
    "RNG = 0\n",
    "classifiers = {\n",
    "    \"LogRegr\": LogisticRegression(random_state=0),\n",
    "    \"SVC_rbf\": SVC(kernel='rbf'),\n",
    "    \"Perceptron\": Perceptron(tol=1e-3, random_state=0), \n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=5, random_state = RNG), \n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(max_depth=5, random_state=RNG),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(max_depth=5, random_state=RNG),\n",
    "    \"MLPClassifier\": MLPClassifier(random_state=1, activation='tanh', hidden_layer_sizes=(100, 100), max_iter=1000)\n",
    "}\n",
    "\n",
    "clf_styles = {\n",
    "    \"LogRegr\": {\"name\": \"Log. Regr.\", \"marker\": \"*\", \"linestyle\": \"-\"}, \n",
    "    \"SVC_rbf\": {\"name\": \"SVM\", \"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "    \"Perceptron\": {\"name\": \"Perceptron\", \"marker\": \"D\", \"linestyle\": \"-\"}, \n",
    "    \"DecisionTreeClassifier\": {\"name\": \"Decision Tree\", \"marker\": \"v\", \"linestyle\": \"-\"}, \n",
    "    \"GradientBoostingClassifier\": {\"name\": \"Gradient Boosting\", \"marker\": \"X\", \"linestyle\": \"-\"},\n",
    "    \"RandomForestClassifier\": {\"name\": \"Random Forest\", \"marker\": \"P\", \"linestyle\": \"-\"},\n",
    "    \"MLPClassifier\": {\"name\": \"DNN\", \"marker\": \"s\", \"linestyle\": \"-\"}\n",
    "}\n",
    "\n",
    "enc_styles = {\n",
    "    \"ComplexIdx\": {\"name\": \"ComplexIdx\", \"marker\": \"*\", \"linestyle\": \"-\"}, \n",
    "    \"Boolean\": {\"name\": \"Boolean\", \"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "    \"Frequency\": {\"name\": \"Frequency\", \"marker\": \"D\", \"linestyle\": \"-\"}, \n",
    "    \"Aggregate\": {\"name\": \"Aggregate\", \"marker\": \"v\", \"linestyle\": \"-\"}, \n",
    "    \"SimpleIdx\": {\"name\": \"SimpleIdx\", \"marker\": \"X\", \"linestyle\": \"-\"},\n",
    "}\n",
    "\n",
    "\n",
    "for noise in noise_list:\n",
    "    for encoder, enc_name in encoders.items():\n",
    "        clf = classifiers['GradientBoostingClassifier']\n",
    "\n",
    "        print(enc_name, clf, noise)\n",
    "        result_dataframe = pd.read_csv(f\"experimental_model_pos_neg_{noise}.csv\")\n",
    "        mean_valore = result_dataframe['valore'].mean()\n",
    "        result_dataframe['valore'].fillna(mean_valore, inplace=True)\n",
    "\n",
    "        enc_df: pd.DataFrame = encoder.fit_transform(result_dataframe)\n",
    "        target_df = result_dataframe[[\"case:concept:name\", \"case:label\"]].drop_duplicates()\n",
    "        enc_df = pd.merge(enc_df, target_df, on=\"case:concept:name\").drop([\"case:concept:name\"], axis=1)\n",
    "\n",
    "        # APPLY padding\n",
    "        padded_list: list = []\n",
    "\n",
    "        def pad_row(row: dict, padding: int):\n",
    "            if padding < min_padding:\n",
    "                return\n",
    "    \n",
    "            row[padded_column_name] = padding\n",
    "            patterns = [rf\"_{padding}$\", rf\"_{padding}_\"]\n",
    "    \n",
    "            for col_name in enc_df.columns:\n",
    "                for pattern in patterns:\n",
    "                    if re.search(pattern, col_name, re.IGNORECASE) is not None:\n",
    "                        row[col_name] = 0\n",
    "\n",
    "            padded_list.append(row)   \n",
    "            return pad_row(row.copy(), padding - 1)\n",
    "\n",
    "        for index in enc_df.index:\n",
    "            pad_row(dict(enc_df.loc[index].copy()), max_padding)\n",
    "\n",
    "        padded_df: pd.DataFrame = pd.DataFrame(padded_list)\n",
    "        padded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        x_cols = list(padded_df.columns)\n",
    "        x_cols.remove('case:label')\n",
    "        y_cols = ['case:label', padded_column_name]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(padded_df[x_cols], padded_df[y_cols], test_size=0.2, random_state = RNG)\n",
    "        y_train = y_train.drop(axis=1, labels=[padded_column_name])\n",
    "        x_train = x_train.drop(axis=1, labels=[padded_column_name])\n",
    "\n",
    "        x_test_dict = {}\n",
    "        y_test_dict = {}\n",
    "\n",
    "        for padding in range(min_padding, max_padding + 1):\n",
    "            x_test_dict[padding] = x_test[x_test[padded_column_name] == padding].copy().drop(axis=1, labels=[padded_column_name])\n",
    "            y_test_dict[padding] = y_test[y_test[padded_column_name] == padding].copy().drop(axis=1, labels=[padded_column_name])\n",
    "\n",
    "        padding_dict[enc_name] = []\n",
    "        f1_score_dict[enc_name] = []\n",
    "    \n",
    "        clf.fit(x_train, y_train.values.ravel())\n",
    "            \n",
    "        for padding in range(min_padding, max_padding):\n",
    "            filtered_x_test = x_test_dict[padding]\n",
    "            filtered_y_test = y_test_dict[padding]\n",
    "            y_pred = clf.predict(filtered_x_test) \n",
    "        \n",
    "            padding_dict[enc_name].append(padding)\n",
    "            f1_score_dict[enc_name].append(round(f1_score(list(filtered_y_test[\"case:label\"]), y_pred, average=\"binary\", pos_label=\"Positive\"), 5))\n",
    "\n",
    "    plt.style.use('paper.mplstyle')\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "\n",
    "    for name in padding_dict.keys():\n",
    "        paddings = padding_dict[name]\n",
    "        f1_scores = f1_score_dict[name]\n",
    "        plt.plot(paddings, f1_scores, label=enc_styles[name][\"name\"], marker=enc_styles[name][\"marker\"], linestyle=enc_styles[name][\"linestyle\"])\n",
    "\n",
    "    plt.title(f\"F1 score with {noise}\\\\% of noise\")\n",
    "    plt.xlabel(\"Prefix length\")\n",
    "    plt.ylim(0.35, 1.02)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"F1_{noise}_encoders.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c4a5a-2b3b-4505-b079-e2b356f447d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Declare4Py.Encodings.Aggregate import Aggregate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "max_padding = max_ev\n",
    "min_padding = 3\n",
    "padded_column_name = \"padding_len\"\n",
    "name = \"NULL\"\n",
    "\n",
    "RNG = 0\n",
    "\n",
    "noise_list = [0, 5, 10, 15]\n",
    "\n",
    "padding_dict = {}\n",
    "f1_score_dict = {}\n",
    "\n",
    "encoders = {Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], boolean=True): \"Boolean\",\n",
    "            Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], boolean=False): \"Frequency\",\n",
    "            Aggregate(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], num_cols=['valore', 'age'], boolean=False, aggregation_functions=['min', 'mean', 'max']): \"Aggregate\",\n",
    "            IndexBased(case_id_col=\"case:concept:name\", cat_cols=['concept:name'], create_dummies=True): \"SimpleIdx\",\n",
    "            IndexBased(case_id_col=\"case:concept:name\", cat_cols = ['concept:name'], num_cols=['valore', 'age'], create_dummies=True): \"ComplexIdx\"}\n",
    "\n",
    "RNG = 0\n",
    "classifiers = {\n",
    "    \"LogRegr\": LogisticRegression(random_state=0),\n",
    "    \"SVC_rbf\": SVC(kernel='rbf'),\n",
    "    \"Perceptron\": Perceptron(tol=1e-3, random_state=0), \n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=5, random_state = RNG), \n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(max_depth=5, random_state=RNG),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(max_depth=5, random_state=RNG),\n",
    "    \"MLPClassifier\": MLPClassifier(random_state=1, activation='tanh', hidden_layer_sizes=(100, 100), max_iter=1000)\n",
    "}\n",
    "\n",
    "clf_styles = {\n",
    "    \"LogRegr\": {\"name\": \"Log. Regr.\", \"marker\": \"*\", \"linestyle\": \"-\"}, \n",
    "    \"SVC_rbf\": {\"name\": \"SVM\", \"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "    \"Perceptron\": {\"name\": \"Perceptron\", \"marker\": \"D\", \"linestyle\": \"-\"}, \n",
    "    \"DecisionTreeClassifier\": {\"name\": \"Decision Tree\", \"marker\": \"v\", \"linestyle\": \"-\"}, \n",
    "    \"GradientBoostingClassifier\": {\"name\": \"Gradient Boosting\", \"marker\": \"X\", \"linestyle\": \"-\"},\n",
    "    \"RandomForestClassifier\": {\"name\": \"Random Forest\", \"marker\": \"P\", \"linestyle\": \"-\"},\n",
    "    \"MLPClassifier\": {\"name\": \"DNN\", \"marker\": \"s\", \"linestyle\": \"-\"}\n",
    "}\n",
    "\n",
    "enc_styles = {\n",
    "    \"ComplexIdx\": {\"name\": \"ComplexIdx\", \"marker\": \"*\", \"linestyle\": \"-\"}, \n",
    "    \"Boolean\": {\"name\": \"Boolean\", \"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "    \"Frequency\": {\"name\": \"Frequency\", \"marker\": \"D\", \"linestyle\": \"-\"}, \n",
    "    \"Aggregate\": {\"name\": \"Aggregate\", \"marker\": \"v\", \"linestyle\": \"-\"}, \n",
    "    \"SimpleIdx\": {\"name\": \"SimpleIdx\", \"marker\": \"X\", \"linestyle\": \"-\"},\n",
    "}\n",
    "\n",
    "\n",
    "for noise in noise_list:\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        encoder = IndexBased(case_id_col=\"case:concept:name\", cat_cols = ['concept:name'], num_cols=['valore', 'age'], create_dummies=True)\n",
    "\n",
    "        print(encoder, clf_name, noise)\n",
    "        result_dataframe = pd.read_csv(f\"experimental_model_pos_neg_{noise}.csv\")\n",
    "        mean_valore = result_dataframe['valore'].mean()\n",
    "        result_dataframe['valore'].fillna(mean_valore, inplace=True)\n",
    "\n",
    "        enc_df: pd.DataFrame = encoder.fit_transform(result_dataframe)\n",
    "        target_df = result_dataframe[[\"case:concept:name\", \"case:label\"]].drop_duplicates()\n",
    "        enc_df = pd.merge(enc_df, target_df, on=\"case:concept:name\").drop([\"case:concept:name\"], axis=1)\n",
    "\n",
    "        # APPLY padding\n",
    "        padded_list: list = []\n",
    "\n",
    "        def pad_row(row: dict, padding: int):\n",
    "            if padding < min_padding:\n",
    "                return\n",
    "    \n",
    "            row[padded_column_name] = padding\n",
    "            patterns = [rf\"_{padding}$\", rf\"_{padding}_\"]\n",
    "    \n",
    "            for col_name in enc_df.columns:\n",
    "                for pattern in patterns:\n",
    "                    if re.search(pattern, col_name, re.IGNORECASE) is not None:\n",
    "                        row[col_name] = 0\n",
    "\n",
    "            padded_list.append(row)   \n",
    "            return pad_row(row.copy(), padding - 1)\n",
    "\n",
    "        for index in enc_df.index:\n",
    "            pad_row(dict(enc_df.loc[index].copy()), max_padding)\n",
    "\n",
    "        padded_df: pd.DataFrame = pd.DataFrame(padded_list)\n",
    "        padded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        x_cols = list(padded_df.columns)\n",
    "        x_cols.remove('case:label')\n",
    "        y_cols = ['case:label', padded_column_name]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(padded_df[x_cols], padded_df[y_cols], test_size=0.2, random_state = RNG)\n",
    "        y_train = y_train.drop(axis=1, labels=[padded_column_name])\n",
    "        x_train = x_train.drop(axis=1, labels=[padded_column_name])\n",
    "\n",
    "        x_test_dict = {}\n",
    "        y_test_dict = {}\n",
    "\n",
    "        for padding in range(min_padding, max_padding + 1):\n",
    "            x_test_dict[padding] = x_test[x_test[padded_column_name] == padding].copy().drop(axis=1, labels=[padded_column_name])\n",
    "            y_test_dict[padding] = y_test[y_test[padded_column_name] == padding].copy().drop(axis=1, labels=[padded_column_name])\n",
    "\n",
    "        padding_dict[clf_name] = []\n",
    "        f1_score_dict[clf_name] = []\n",
    "    \n",
    "        clf.fit(x_train, y_train.values.ravel())\n",
    "            \n",
    "        for padding in range(min_padding, max_padding):\n",
    "            filtered_x_test = x_test_dict[padding]\n",
    "            filtered_y_test = y_test_dict[padding]\n",
    "            y_pred = clf.predict(filtered_x_test) \n",
    "        \n",
    "            padding_dict[clf_name].append(padding)\n",
    "            f1_score_dict[clf_name].append(round(f1_score(list(filtered_y_test[\"case:label\"]), y_pred, average=\"binary\", pos_label=\"Positive\"), 5))\n",
    "\n",
    "    plt.style.use('paper.mplstyle')\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "\n",
    "    for name in padding_dict.keys():\n",
    "        paddings = padding_dict[name]\n",
    "        f1_scores = f1_score_dict[name]\n",
    "        plt.plot(paddings, f1_scores, label=clf_styles[name][\"name\"], marker=clf_styles[name][\"marker\"], linestyle=clf_styles[name][\"linestyle\"])\n",
    "\n",
    "    plt.title(f\"F1 score with {noise}\\\\% of noise\")\n",
    "    plt.xlabel(\"Prefix length\")\n",
    "    plt.ylim(0.45, 1.02)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"F1_{noise}_classifiers.pdf\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
