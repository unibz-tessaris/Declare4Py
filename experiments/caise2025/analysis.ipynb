{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Look for data in each subdirectory of `OUTPUD_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path('output')\n",
    "\n",
    "\n",
    "DATA_DIRS: list[Path] = [p for p in OUTPUT_DIR.iterdir() if p.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "RAW_DATA: list[dict] = []\n",
    "\n",
    "for data_dir in DATA_DIRS:\n",
    "    data = []\n",
    "    for rfile in data_dir.glob('*_results.json'):\n",
    "        with rfile.open() as fp:\n",
    "            result = json.load(fp)\n",
    "            result['src'] = data_dir.name\n",
    "            data.append(result)\n",
    "    if len(data) < 1 and data_dir.joinpath('results.json').exists():\n",
    "        with data_dir.joinpath('results.json').open() as fp:\n",
    "            results = json.load(fp)\n",
    "            for result in results:\n",
    "                result['src'] = data_dir.name\n",
    "                data.append(result)\n",
    "\n",
    "    RAW_DATA.extend(data)\n",
    "\n",
    "RAW_DATA_df = pd.json_normalize(RAW_DATA)\n",
    "\n",
    "RAW_DATA_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY = RAW_DATA_df[['src', 'id', 'generator']].copy()\n",
    "\n",
    "SUMMARY['threshold'] = RAW_DATA_df['params.threshold']\n",
    "SUMMARY['randomised'] = ((RAW_DATA_df['generator'] == 'PBLogGeneratorRandom') | RAW_DATA_df['params.randomise'])\n",
    "SUMMARY['model'] = RAW_DATA_df['params.model']\n",
    "SUMMARY['case_size'] = RAW_DATA_df['params.events']\n",
    "SUMMARY['log_size'] = RAW_DATA_df['params.traces']\n",
    "SUMMARY['generated'] = RAW_DATA_df['cases']\n",
    "SUMMARY['coverage'] = RAW_DATA_df['cases']/RAW_DATA_df['params.traces']\n",
    "SUMMARY['time'] = RAW_DATA_df['stats.times.total']\n",
    "SUMMARY['timeout'] = RAW_DATA_df['stats.timedout']\n",
    "SUMMARY['hamming'] = RAW_DATA_df['control_flow.hamming']\n",
    "SUMMARY['levenshtein'] = RAW_DATA_df['control_flow.levenshtein']\n",
    "\n",
    "SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write summary to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "SUMMARY.to_csv(OUTPUT_DIR / f'summary_{datetime.now(tz=None).strftime('%Y-%m-%dT%H%M%S')}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "Show results for each generator class and configuration, tables are summarised by log and case sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def show_table(key: str) -> None:\n",
    "    for k, df in SUMMARY.sort_values(by=['generator', 'randomised', 'threshold', 'src']).groupby(by=['src', 'generator', 'randomised', 'threshold'], dropna=False):\n",
    "        timeout_style = lambda _: df.pivot(index='log_size', columns='case_size', values='timeout').map(lambda x: 'background-color: pink' if x else '')\n",
    "        pivot_df = df.pivot(index='log_size', columns='case_size', values=key)\n",
    "        display(pivot_df.style\n",
    "                .set_caption(f'{k[1]}(rnd={k[2]}, threshold={k[3]}) src: {k[0]}')\n",
    "                .apply(timeout_style, axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_table('coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_table('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_table('levenshtein')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated log size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_table('generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_table('timeout')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
